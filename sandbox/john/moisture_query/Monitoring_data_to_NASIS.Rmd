---
title: "Loading Monitoring Data into NASIS"
author: "John R. Hammerly"
date: "June 30, 2017"
output:
  html_document:
          toc: true
          toc_depth: 4
          toc_float: true
params:
  mdata: "C:/Users/john.hammerly/ownCloud/water_monitor_data/000009BEC048_20120919_1128.txt"
  office: "11-ATL"
  usiteid: "2013IA001001"
  project: "DSP - MLRA 108D - Shelby, clay loam"
  projectid: "201711ATL999"
  sensor: ""
  bottomdepth: "210"
  sensordepth: "210"
---
###Description

There is a multitude of variability in monitoring data throughout the soil science discipline.  Differences in installation, instrumentation, and collection frequency are just a few examples.  This document provides guidance for loading monitoring data into the National Soil Information System (NASIS).  Although there are many different ways to accomplish this task, the repeatability and versatility of R works well for this purpose.

####Assumptions

Before you get started working through this document, you should first consider the following assumptions taken in creating this document:

1. The monitoring data is an accurate representation of a wet soil moisture condition
2. Data collection has completed and it is ready to archive in NASIS and analyzed in R
3. NASIS is installed and you have sufficient privileges to edit the database

If your situation does not meet the assumptions above, you will need to tailor the instructions to fit your needs.  This could involve additional data manipulations in Excel, performing ground truth activities, and/or changing functions and before loading into Excel or NASIS.

The instructions were tested and confirmed functional using NASIS data model 7.3.3.

###Data Exploration

####Load Monitoring Data
In the following example we will be using raw data collected from a water table monitoring site located in Adair County, Iowa. The raw data is stored in a .txt file.  This file can easily be viewed in R using the following code:

```{r Read Monitoring Data}
# Use the knit with parameters option in the knit dropdown menu in R Studio to use your own data.
read.csv(params$mdata, nrows=20) # Show the first 20 rows
```

The general format of the file contains several lines of data as a header in the file, such as the instrument serial number and date when the data was collected from the instrument.  Following the header, the names of the data columns are listed separated by commas, followed by the rows of data.  Let's create a data.frame object in R using only the data after the header.

```{r Create a data.frame}
monitor_data<-read.csv(params$mdata, header=FALSE, skip=8, #skip the rows without observation data 
col.names=c("date","time","depth","units"), as.is=TRUE) #assign column names
```

The skip=8 option of read.csv tells R to begin reading the data at line 9 of the data.  The header rows, the column names, and the first 2 rows of the data were not included in the data.frame.  These rows were either not needed, or erroneous data.

Let's view the first 10 rows of the new data.frame.

```{r View data.table1, echo=F}
library(knitr)
kable(monitor_data[1:10,])
```

####Organize Data

Notice the monitoring instrument is collecting depths multiple times each day.  This can result in a large amount of repeated data.  We can calculate mean values each day using R.

```{r Calculate daily means}
monitor_data_daily<-aggregate(cbind(depth)~date,data=monitor_data,FUN=mean)
```

```{r View data.table2, echo=F}
kable(monitor_data_daily[1:10,])
```

Looking at the result you can see the data is now summarized by day, but is now out of chronological order.  To clean this data up we can use the code below.

```{r Clean up data}
# convert date column to date type
monitor_data_daily_convert<-data.frame(as.Date(monitor_data_daily$date, format="%m/%d/%Y"), round(monitor_data_daily$depth*-1*2.54)) # convert depths to positive centimeters

# rename columns to match NASIS
names(monitor_data_daily_convert)<-list("obsdate","soimoistdept")

# Replace values less than zero
monitor_data_daily_convert$soimoistdept[monitor_data_daily_convert$soimoistdept<0]<-0

# Order by date
monitor_data_daily_convert<-monitor_data_daily_convert[order(monitor_data_daily_convert$obsdate),]

# Reassign row names based on new ordering
row.names(monitor_data_daily_convert) <- 1:nrow(monitor_data_daily_convert)
monitor_data_daily_convert$seqnum<-seq.int(nrow(monitor_data_daily_convert))

# Reorder columns
monitor_data_daily_convert<-monitor_data_daily_convert[,c(3,1,2)]
```

```{r View data.table3, echo=F}
kable(monitor_data_daily_convert[1:10,])
```

####Make Tables

The chunk of code above accomplished a several different tasks.

1. Converted the dates from a character string into a date type
2. Changed negative inch depths to positive centimeters
3. Renamed columns
4. Replaced any negative values with zero
5. Reordered the rows by date
6. Created a sequence column
7. Reordered the columns

The data is looking much more useable now.  Since our end goal is to load this data into NASIS, we need still need to add some data columns.

```{r Create data in sitesoilmoist table for Excel}
# Rename data.frame
sitesoilmoist_table<-monitor_data_daily_convert

# Create bottom depth, for this sensor, the bottom depth is the lowest the sensor will register a reading
sitesoilmoist_table$soimoistdepb<-as.integer(params$bottomdepth)

# Create sensor depth, this is also the lowest the sensor will register a reading
sitesoilmoist_table$soilmoistsensordepth<-as.numeric(params$sensordepth)

# If the top depth, bottom depth and sensor depth are equal, leave the moisture status NA, otherwise assign a wet status.

sitesoilmoist_table<- transform(sitesoilmoist_table, obssoimoiststat=ifelse(soimoistdept==soimoistdepb & soimoistdepb==soilmoistsensordepth, NA, "wet"))

# Add a usiteid column
sitesoilmoist_table$usiteid<-params$usiteid

# Add an observation date kind column
sitesoilmoist_table$obsdatekind<-"actual site observation date"

# Add a datacollecter column
sitesoilmoist_table$datacollector<-params$office

# Add ProjectName
sitesoilmoist_table$projectname<-params$project

# Add projectid
sitesoilmoist_table$uprojectid<-params$projectid

# Add sensorkind
sitesoilmoist_table$soilmoistsensorkind<-params$sensor

# Reorder columns
sitesoilmoist_table<-sitesoilmoist_table[,c(7,2,8,9,10,11,3,4,5,12,6)]

# Convert dates to characters
sitesoilmoist_table$obsdate<-as.character(sitesoilmoist_table$obsdate)
```

```{r View data.table4, echo=F}
kable(sitesoilmoist_table[1:10,])
```

The table now contains all the data needed for loading into NASIS.  But we first need to add the data to an excel document.

###Build Excel Document

R has a useful library for reading and writing to xlsx files called xlsx.  The special format required by the NASIS excel upload process means we need to create a new workbook rather than use an existing one.

```{r Export data.frame to xlsx, message=F}
library(xlsx)

# Create an empty workbook
wb<-createWorkbook()

# Create a sheet within the workbook
sheet<-createSheet(wb, sheetName="SiteSoilMoisture")

# Add monitoring data
addDataFrame(sitesoilmoist_table, sheet, startRow=3, startColumn=3, row.names=F)

# Create a data.frame with the name and version of the workbook required for NASIS
wbnamecell<-data.frame("SiteSoilMoisture","1.0")

# Add the required NASIS data.frame to the workbook
addDataFrame(wbnamecell, sheet, startRow=1, startColumn=1, col.names=F,row.names=F)

# Save the workbook
saveWorkbook(wb, "C:/workspace/SiteSoilMoisture.xlsx")

```

###Import Excel Document into NASIS

If the site or project for the data already exist in NASIS you will need to check them out first.

1. Open NASIS and select Import Excel File from the NASIS menu
2. Select the file you created in R in the open browse window
3. Upload changes to National Database
4. Check in All

**Congratulations!**

*You have successfully loaded your monitoring data into NASIS.*